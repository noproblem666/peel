system {
    hadoop-2 {
        user = ${system.default.user}
        group = ${system.default.group}
        path {
            isShared = ${system.default.path.isShared}
            archive.dst = ${app.path.systems}
            config = ${system.hadoop-2.path.home}"/etc/hadoop"
            log = ${system.hadoop-2.path.home}"/logs"
            input = ${system.hadoop-2.config.core.fs.default.name}"/tmp/input"
            output = ${system.hadoop-2.config.core.fs.default.name}"/tmp/output"
        }
        format = true
        startup {
            max.attempts = ${system.default.startup.max.attempts}
            polling {
                counter = ${system.default.startup.polling.counter}
                interval = ${system.default.startup.polling.interval}
            }
        }
        config {
            # put list of masters
            masters = ${system.default.config.masters}
            # put list of slaves
            slaves = ${system.default.config.slaves}
            # hadoop-env.sh entries
            env {
                JAVA_HOME = ${system.default.config.java.home}
                HADOOP_INSTALL = ${system.hadoop-2.path.home}
                # directory where process IDs are stored
                HADOOP_PID_DIR = "/tmp/hadoop-2/pid"
                # avoids loading wrong native library in the default case
                # override with /lib/native if lib exists
                HADOOP_COMMON_LIB_NATIVE_DIR = "$HADOOP_INSTALL/lib/native"
            }
            # core-site.xml entries
            core {
                fs.default.name = "hdfs://localhost:9000"
            }
            # hdfs-site.xml entries
            hdfs {
                dfs.replication = 1
                dfs.namenode.name.dir = "file:///tmp/hdfs-2/name"
                dfs.datanode.data.dir = "file:///tmp/hdfs-2/data"
            }
            # mapred-site.xml entries
            mapred {
                mapred.job.tracker._root_ = "localhost:9001"
                mapred.tasktracker.map.tasks.maximum = ${system.default.config.parallelism.per-node}
                mapred.tasktracker.reduce.tasks.maximum = ${system.default.config.parallelism.per-node}
                mapreduce.map.java.opts = "-Xmx2g -Xms2g -Xmn200m"
                mapreduce.reduce.java.opts = "-Xmx2g -Xms2g -Xmn200m"
                mapreduce.map.memory.mb = 1024
                mapreduce.reduce.memory.mb = 1024
                mapreduce.task.io.sort.mb = 100
                mapreduce.framework.name = "yarn"
            }
        }
    }
}
